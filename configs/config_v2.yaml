metadata: 
  name: "modolo_margin_v2"
  devices: auto
  debug: true
  batch_size: 16
logger:
  _target_: "pytorch_lightning.loggers.wandb.WandbLogger"
  project: ${metadata.name}
  offline: ${metadata.debug}



tokenizer:
  _target_: tokenizers.Tokenizer.from_file
  path: models/configs/smiles_tokenizer.json

model:
  _target_: "models.modolo.Modolo"
  transformer_encoder: 
  transformer_decoder: 
    _target_: models.transformer.TransformerDecoder
    tokenizer: ${tokenizer}
    embedding_dim: 256
    hidden_size: 128
    nhead: 4
    n_layers: 2
    max_length: 128
  interaction_encoder:
    _target_: models.interaction_encoder.InteractionEncoder
    output_dim: ${model.transformer_decoder.embedding_dim}
  graph_encoder: 
    _target_: models.graph_encoder.GraphEncoder
    in_channels: 96
    edge_channels: 96
    hidden_channels: [96,192,384]
    out_channels: ${model.transformer_decoder.embedding_dim}
    attention_groups: [12,24,48,32]
    version: 2
    dropout: 0.1
    max_length: 128
    graph_embedder: 
      _target_: models.graph_embedder.GraphEmbedder
      distance_embed_dim: 16
      cross_distance_embed_dim: 16
      lig_max_radius: 5
      rec_max_radius: 10
      cross_max_distance: 20
      lig_feature_dims: 
        _target_: "datasets.process_chem.features.get_lig_feature_dims"
      lig_edge_feature_dim: 4
      lig_emb_dim: ${model.graph_encoder.in_channels}
      rec_feature_dims:  
        _target_: "datasets.process_chem.features.get_rec_residue_feature_dims"
      atom_feature_dims:  
        _target_: "datasets.process_chem.features.get_rec_atom_feature_dims"
      prot_emd_dim: ${model.graph_encoder.in_channels}
      dropout: 0.3
      lm_embedding_dim: 1280


lightning:
  _target_: "models.modolo_lightning.ModoloLightning"
  lr: 1e-4
  weight_decay: 1e-4
  num_gen_samples: 10
  handle_inactive: penalty
  tokenizer: ${tokenizer}

train:
  batch_size: ${metadata.batch_size}
  trainer:
    _target_: "pytorch_lightning.Trainer"
    devices: ${metadata.devices}
    num_sanity_val_steps: 1
    max_epochs: 200
    check_val_every_n_epoch: 5
    # strategy: 'ddp_find_unused_parameters_true'


  val_dataset:
    _target_: "datasets.fsmol_dock_clf.FsDockClfDataset"
    root: "data/fsdock/clfs/valid"
    tasks: "data/fsdock/valid_tasks.csv"
    only_inactive: false
    core_weight: 0.7
    min_roc_auc: 0.70

  train_dataset:
    _target_: "datasets.partitioned_fsmol_dock.FsDockDatasetPartitioned"
    root: "data/fsdock/valid"
    tasks: "data/fsdock/valid_tasks.csv"
    core_weight: 0.7
    random_max_angle: 0.3
  
  # train_dataset:
  #   _target_: "datasets.partitioned_fsmol_dock.FsDockDatasetPartitioned"
  #   root: "data/fsdock/train"
  #   tasks: "data/fsdock/train_tasks.csv"
  #   core_weight: 0.7
  #   random_max_angle: 0.3
  
  sampler:
    _target_: "datasets.custom_distributed_sampler.CustomTaskDistributedSampler"
    shuffle: true
    task_size: ${metadata.batch_size}
    stream: true
    num_replicas: 1
    rank: 0


test:
  dataset:
    _target_: "datasets.fsmol_dock_clf.FsDockClfDataset"
    root: "data/fsdock/clfs/test"
    tasks: "data/fsdock/test_tasks.csv"
    only_inactive: true
    core_weight: 0.7
    min_roc_auc: 0.70
